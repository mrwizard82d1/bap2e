{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. What expression corresponds to the sentence, _The probability of being sunny given is that it is 9th of July of 1816?\n",
    "\n",
    "    p(sunny | 9th of July of 1816)\n",
    "    \n",
    "    However, the product rule states:\n",
    "    \n",
    "    $ p(A, B) = p(A|B)p(B) $\n",
    "    \n",
    "    which can be rearranged to:\n",
    "    \n",
    "    $ p(A|B) = \\frac{p(A, B)}{p(B)} $\n",
    "    \n",
    "    if we replace A with \"sunny\" and B with \"9th of July of 1816,\" then we see that the expression\n",
    "    \n",
    "    $ \\frac{p(sunny, 9th\\ of\\ July\\ of\\ 1816)}{p(9th\\ of\\ July\\ of\\ 1816)} = p(sunny | 9th\\ of\\ July\\ of\\ 1816) $\n",
    "    \n",
    "    Therefore, \n",
    "    \n",
    "    $ \\frac{p(sunny, 9th\\ of\\ July\\ 1816)}{p(9th\\ of\\ July\\ of\\ 1816)} $ also corresponds to the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Show that the probability of choosing a human at random and picking the Pope is not the same as the probability of\n",
    " the Pope being human.\n",
    " \n",
    "    The probabilities of interest are:\n",
    "\n",
    "        - The probability that you pick the Pope given that you pick a human: p(Pope | human)\n",
    "        - The probability that you pick a humane given that you pick the Pope: p(human | Pope)\n",
    "\n",
    "    The population of the world as of March 2020 is estimated at 7.8 billion people. The Pope is exactly one of those \n",
    "    people. Consequently, \n",
    "\n",
    "    $p(Pope | human) = \\frac{1}{7,800,000,000}$\n",
    "        \n",
    "    Assuming we are not in *Futurama*, then\n",
    "\n",
    "    $p(human | Pope) = 1$\n",
    "        \n",
    "    If we live in *Futurama*, then the calculations both change because the Pope is **not** human.\n",
    "\n",
    "    $p(human | Pope) = 0$<br/>\n",
    "    $p(Pope | human) = 0$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. In the following definition of a probabilistic model, identify the prior and the likelihood:\n",
    "\n",
    "    $y _{i} \\sim Normal(\\mu, \\sigma)$<br/>\n",
    "    $\\mu \\sim Normal(0, 10)$<br/>\n",
    "    $\\sigma \\sim HalfNormal(25)$<br/>\n",
    "\n",
    "    - Likelihood \n",
    "        - $y _{i} \\sim Normal(\\mu, \\sigma)$<br/>\n",
    "\n",
    "    - Prior \n",
    "        - $\\mu \\sim Normal(0, 10)$ \n",
    "        - $\\sigma \\sim HalfNormal(25)$<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. In the previous model, how many parameters will the posterior have? Compare it to the model for the \n",
    "coin-flipping problem.\n",
    "\n",
    "    The posterior in the previous problem has two parameters, $\\mu$ and $\\sigma$.\n",
    "    \n",
    "    In the coin-flipping problem, the posterior only has a single parameter, $\\theta$, modeling the \n",
    "    bias of the coin.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5. Write the Bayes' theorem for the model in exercise 3.\n",
    "\n",
    "    $p(\\mu, \\sigma | y) = \\frac{p(y | \\mu, \\sigma) p(\\mu) p(\\sigma)}{p(y)}$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "6. Let's suppose we have two coins: when we toss the first coin, half of the time it lands tails and \n",
    "half of the time on heads. The other coin is a _loaded coin_ that always lands on heads. If we take one of the\n",
    "coins at random and get a head, what is the probability that is coin is the unfair one.\n",
    "\n",
    "    Here are our symbols for this problem:\n",
    "    \n",
    "        - F fair coin\n",
    "        - U unfair coin\n",
    "        - H heads\n",
    "        - T tails\n",
    "        \n",
    "    If we use Bayes' rule to model this problem, we have:\n",
    "    \n",
    "    $p(U | H) = \\frac{p(H | U) p(U)}{p(H | U) p(U) + p(H | F) p(F)}$\n",
    "    \n",
    "    If we then substitute what we know, this equation becomes:\n",
    "    \n",
    "    $p(U | H) = \\frac{1 \\times ^1/_2}{(1 \\times ^1/_2) + (^1/_2 \\times ^1/_2)}$\n",
    "    \n",
    "    Simplifying yields\n",
    "    \n",
    "    $ p(U | H) = \\frac {^1/_2} {^1/_2 + ^1/_4} $ <br/>\n",
    "    $ p(U | H) = \\frac {^1/_2} {^3/_4} $ <br/>\n",
    "    $ p(U | H) = \\,^2/_3 $\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "7. Modify the code that generated  _Figure 1.5_ in order to add a dotted line showing the observed rate \n",
    "(heads / number of tosses). Compare the location of this line to the mode of the posteriors in each subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "n_trials = [0, 1, 2, 3, 4, 8, 16, 32, 50, 150]\n",
    "data = [0, 1, 1, 1, 1, 4, 6, 9, 13, 48]\n",
    "theta_actual = 0.35\n",
    "\n",
    "beta_params = [(1, 1), (20, 20), (1, 4)]  # Uniform, central tendency, weighted toward tails\n",
    "dist = scipy.stats.beta\n",
    "x = np.linspace(0, 1, 200)\n",
    "\n",
    "for ndx, N in enumerate(n_trials):\n",
    "    if ndx == 0:\n",
    "        # Plotting the priors\n",
    "        plt.subplot(4, 3, 2)\n",
    "        plt.xlabel('Θ')\n",
    "    else:\n",
    "        # Plotting the posteriors for different trials\n",
    "        plt.subplot(4, 3, ndx + 3)\n",
    "        plt.xticks([])\n",
    "    y = data[ndx]\n",
    "    for (a_prior, b_prior) in beta_params:\n",
    "        p_theta_given_y = dist.pdf(x, a_prior + y, b_prior + N - y)\n",
    "        plt.fill_between(x, 0, p_theta_given_y, alpha=0.7)\n",
    "        if ndx != 0:\n",
    "            plt.axvline(y / n_trials[ndx], ymax=0.3, color='k', linestyle='dashed')\n",
    "    plt.axvline(theta_actual, ymax=0.3, color='k')\n",
    "    plt.plot(0, 0, label=f'{N:4d} trials\\n{y:4d} heads', alpha=0)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 12)\n",
    "    plt.legend()\n",
    "    plt.yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At very small values, the observed rate of heads seems to bear no relationship to the mode of the posteriors; \n",
    "however as the number of trials increases and the posteriors approach each other, the mode of the posterior(s)\n",
    "approaches this value - even as this value approaches the actual rate of the generating distribution. \n",
    "\n",
    "This observation is consistent with the Central Limit Theorem. As the posteriors approach a Gaussian with the \n",
    "mean / mode at the actual bias, the mean and the mode approach each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "8. Try re-plotting _Figure 1.5_ using other priors (`beta_params`) and other data (trials and data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Different priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "n_trials = [0, 1, 2, 3, 4, 8, 16, 32, 50, 150]\n",
    "data = [0, 1, 1, 1, 1, 4, 6, 9, 13, 48]\n",
    "theta_actual = 0.35\n",
    "\n",
    "beta_params = [(1, 1), (40, 40), (1, 4), (4, 1)]  # Uniform, central tendency, tails-bias, heads-bias\n",
    "dist = scipy.stats.beta\n",
    "x = np.linspace(0, 1, 200)\n",
    "\n",
    "for ndx, N in enumerate(n_trials):\n",
    "    if ndx == 0:\n",
    "        # Plotting the priors\n",
    "        plt.subplot(4, 3, 2)\n",
    "        plt.xlabel('Θ')\n",
    "    else:\n",
    "        # Plotting the posteriors for different trials\n",
    "        plt.subplot(4, 3, ndx + 3)\n",
    "        plt.xticks([])\n",
    "    y = data[ndx]\n",
    "    for (a_prior, b_prior) in beta_params:\n",
    "        p_theta_given_y = dist.pdf(x, a_prior + y, b_prior + N - y)\n",
    "        plt.fill_between(x, 0, p_theta_given_y, alpha=0.7)\n",
    "        if ndx != 0:\n",
    "            plt.axvline(y / n_trials[ndx], ymax=0.3, color='k', linestyle='dashed')\n",
    "    plt.axvline(theta_actual, ymax=0.3, color='k')\n",
    "    plt.plot(0, 0, label=f'{N:4d} trials\\n{y:4d} heads', alpha=0)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 12)\n",
    "    plt.legend()\n",
    "    plt.yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Interesting, but not surprising when you consider it, that the \"hardest\" prior to \"move\" is the very high central \n",
    "tendency. This behavior recommends choosing uninformative to mildly informative priors. As in life, an \n",
    "\"opinionated\" prior makes it difficult to \"change your mind.\"\n",
    "\n",
    "Interesting, too, that both the biased priors, toward tails and toward heads, converge quickly toward the \n",
    "\"real\" value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other data\n",
    "\n",
    "First, I generate other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def fib(n):\n",
    "    a, b = 0, 1\n",
    "    for _ in range(n):\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "        \n",
    "n_trials = sorted(list(set(fib(17))))\n",
    "print(f'(Fibonacci) Trials={n_trials}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "theta_actual = 0.35\n",
    "data = []\n",
    "while not data:\n",
    "    candidate_data = [scipy.stats.binom.rvs(n, theta_actual) for n in n_trials]\n",
    "    data = candidate_data\n",
    "print(f'Data={data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Be wary! Many of the constants specified here (figure size, subplot count and array) on \n",
    "# both the number of trials (17) specified previously and the display \"device.\"\n",
    "\n",
    "plt.figure(figsize=(14.4, 8.9))\n",
    "\n",
    "beta_params = [(1, 1), (20, 20), (1, 4)]  # Uniform, central tendency, tails-bias, heads-bias\n",
    "dist = scipy.stats.beta\n",
    "x = np.linspace(0, 1, 200)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.025, hspace=0.025)\n",
    "for ndx, N in enumerate(n_trials):\n",
    "    if ndx == 0:\n",
    "        # Plotting the priors\n",
    "        plt.subplot(4, 5, 3)\n",
    "        plt.xlabel('Θ')\n",
    "    else:\n",
    "        # Plotting the posteriors for different trials\n",
    "        plt.subplot(4, 5, ndx + 5)\n",
    "        plt.xticks([])\n",
    "    y = data[ndx]\n",
    "    for (a_prior, b_prior) in beta_params:\n",
    "        p_theta_given_y = dist.pdf(x, a_prior + y, b_prior + N - y)\n",
    "        plt.fill_between(x, 0, p_theta_given_y, alpha=0.7)\n",
    "        if ndx != 0:\n",
    "            plt.axvline(y / n_trials[ndx], ymax=0.3, color='k', linestyle='dashed')\n",
    "    plt.axvline(theta_actual, ymax=0.3, color='k')\n",
    "    plt.plot(0, 0, label=f'{N:4d} trials\\n{y:4d} heads', alpha=0)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 30)\n",
    "    plt.legend()\n",
    "    plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Looking at these plots, once the number of trials exceeds 250, increasing the trials does not significantly \n",
    "change the posterior distributions independent of priors and the number of successes (trials).\n",
    "\n",
    "At a very small number of trials, as expected, we see much variation, but it begins \"disappearing\" between\n",
    "20 and 50 trials.\n",
    "\n",
    "I had expected that zeros for a small number of trials would **not** be useful; however, after filtering\n",
    "out trials with more than two zeros, I re-introduced them and found that they were **not** useless  even for \n",
    "these small trials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
